Data Processing Shift Procedures

If you need to run the autopilot for the first time go to README.md and follow the instructions

Run AutoPilot:

1) Make configurations on AirTable for each device.
2) Make global configuration pointing to every device config.
3) If the listeners on different digitizers are not running, follow the listener starting procedures.
4) Make sure the otsdaq webpage says that it is in configured state. If not follow the otsdaq configuring procedures.
5) Make sure the otsdaq is correctly configured for all the digitizers in the otsdaq webpage configuration.
6) Now to run the autopilot, assuming you are already on timingdaq02:
		Go to JARVIS/AutoPilot
		source ~/setup.sh
		./runAutoPilot.sh <Global Configuration number>  <number of runs to take>	example: ./runAutoPilot.sh 1 10


Stop AutoPilot:

1) Go to JARVIS/AutoPilot on timingdaq02. 
2) Run ./StopAutoPilot.sh


Listener Starting Procedures:

* For DT5742:
	1) ssh daq@192.168.133.167, password is timingdaq
	2) Do -- cd lorenzo/TimingBone/ 
	3) Do -- ./TimingController
	4) Make sure it says on the screen that it binds to the socket, if it doesn't then probably the listener is already running somewhere else. 
* For VME:

* For KeySightScope:
	1) ssh -XY daq@timingdaq02.dhcp.fnal.gov
	2) Go to JARVIS/BackEndProcesses/
	3) Open readScopeStatus.py and adjust the scope acquisition parameters.
	4) Through remote desktop make sure the scope is ready for acquisition
	5) To setup the environment for the listener, do
			source ~/otsdaq/setup_ots.sh
	6) Now start the listener using
	 		python readScopeStatus.py


OTSDAQ Configuration Procedures:

* If the otsdaq is not in configured state:
	1) Go to the webpage and configure it.
* If otsdaq is in a failed state:
	1) Do "ssh cmstiming@ftbf-daq-06", if you are not already there 
	2) source cmstiming_setup.sh
	2) Launch the server again using "ots" command
	3) Then go to the webpage and initialize and configure the otsdaq


Run processing on condor:

Copying raw scope data to condor
1) on timingdaq02: open terminal for copying data from scope to EOS ("xrdcpRaw")
2) source ~/SpecialCommands/setup_xrdcp.sh
3) go to JARVIS/RecoProcesses/
4) python StartKeySightScopexrdcpRaw.py

Processing track reconstruction
1) on timingdaq02 open terminal
2) source ~/SpecialCommands/setup_xrdcp.sh
3) go to JARVIS/RecoProcesses/
4) python StartTrackingProcessing.py

Processing Conversion and TimingDAQ on LPC
1) ssh to lpc, with 3 terminals
2) voms-proxy-init --voms cms
3) cd TestBeamReco/JARVIS/RecoProcesses
	a) StartKeySightScopeConversionCondor.py
	b) StartKeySightScopeProcessingCondor.py
	c) StartKeySightScopeWatchCondor.py




Run Auto-Processing locally: 

1) On timingdaq02 : Open 3 terminal windows for VME, DT5742 and KeySight reconstruction respectively (if you are using all three).
2) Go to JARVIS/RecoProcesses/ on all three windows
3) Make sure the following TimingDAQ processing scripts have correct config version hard coded. 
	StartDT5742Processing.py for DT5742
	StartVMEProcessing.py for VME
	StartKeySightScopeProcessing for KeySightScope	
4) Now run the following commands on the three windows
	". DT5742Reco.sh"
	". VMEReco.sh"
	". KeySightScopeReco.sh" 

If you want to run TimingDAQ for two configs, just use VMERecoBTL.sh: It can do TimingDAQ with tracks and without tracks for 2 configs. You can mention the two configs in StartVMEProcessingBTL.py
If the script fails for some reason, use VMEReco.sh with just one configuration


For Reprocessing single run, or a range of runs:

1) On timingdaq02 : Go to JARVIS/RecoProcesses
2) Run the Reprocess scripts for the respective digitizers after hardcoding the range of runs, and the version (if doing timingdaq) correctly.
3) If you want the entries for the scope root files: make sure to source root first before running the keysighscope reprocess script.


Common Failures:
* Tracking could fail due to following reasons:
	Read acknowledgement from the otsdaq "Start: received message:" in autopilot window. If it doesn't say "done" then 
		1) Stop the autopilot
		2) Start OTS server again, and then initialize and configure
		3) Start the autopilot
	Look at the histograms in otsdaq visualizer and make sure they are fine: Look at the trigger and the strip
	Maybe the tracking was fine on Rulinux but it is not copied back to daq02, Check the log to see if this is the case. Reissue the ticket on otsdaq@rulinux04.dhcp.fnal.gov

* Keep checking the run number and if the run number in digitizer listener doesn't match the otsdaq run number
 	 Reissue the ticket on timingdaq02, change the run number in the file /data-08/TestBeam/Users/RunNumber/OtherRuns0NextRunNumber.txt to the next run number from the run table and see if the problem is fixed.
* VME TimingDAQ failure:
	 Make sure the vme rsync is on in workspace 4
* See "N/A" in Olmo's fields:
	 Make sure the RP rsync is on in workspace 4 


If running VME on daq08:

JARVIS on DAQ08 Lives in /home/otsdaq/CMSTimingJarvis/
Data on DAQ08 lives in /home/otsdaq/CMSTimingJarvis/2019_04_April_CMSTiming/
TimingDAQ which is used for processing lives in /home/otsdaq/CMSTimingJarvis/

* Make sure that no otsdaq environment is sourced before you run VMEProcessing and Tracking Reco on DAQ08.
* Make sure not to commit anything from DAQ-08.
* Make sure the paths in AllModules for timingdaq02 and PCCITFNAL01 are commented out.
* Make sure TransferVME is not running on timingdaq02 for the raw VME files.
* Make sure if you are changing the configuration for the VME, you change it here /home/otsdaq/CMSTimingJarvis/TimingDAQ/ on DAQ08
* Also if you want to compile timingdaq source /home/otsdaq/CMSTimingJarvis/setup.sh

If running VME on DAQ02:
* Make sure the TransferVME is progressing in workspace 4 on DAQ02 for the RawVME files.
